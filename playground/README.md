# Playground


**NLP**

- [X] new labels: pondérer chacun des mots: (w'=c1w1+c2w2+c3w3+c4w4)
    - [X] regarder la distance entre mot original et nouveau mot et considérer 
	  les mots dans le rayon
    - [X] Test on pretrained datasets: 
	  - [GloVe](https://github.com/stanfordnlp/GloVe)
	  - [FastText](https://fasttext.cc/docs/en/english-vectors.html)


**Project 1: Unify Datasets**

1. [X] Create Word Embedding / use pretrained word embedding
2. [ ] Encode Each sentence by keeping their most important word (using TF-IDF) et 
   ordonner les mots par ordre d'importance
3. [ ] Créer un cluster des phrases similaires 
       - [ ] Pour chaque cluster, retrouver les mots similaires
       - [ ] Assigner une classe à un cluster


## Ressources

- [X] [Using Pretrained Word Embedding](https://analyticsindiamag.com/hands-on-guide-to-word-embeddings-using-glove/)

